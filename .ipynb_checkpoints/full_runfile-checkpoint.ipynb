{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LRATE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ecb46cf7e233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16_modified\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg16_modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjaja\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_handling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjaja\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/Semantic_Segmentation/jaja/training_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mOUTPUT_SHAPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m104\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_last_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_last_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fcn_logits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcorrect_label_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LRATE' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vgg16.vgg16_modified import vgg16_modified\n",
    "from code.data_processing import data_handling as dh\n",
    "from code.training_functions import optimise, train_nn\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEAT_DIR = './data/train/images'\n",
    "# LABELS_DIR = './data/train/masks'\n",
    "# #VGG_PATH = '/home/paperspace/kaggle/Semantic_Segmentation/vgg16/saved_model_with_dropout'\n",
    "# VGG_PATH = '/home/paperspace/kaggle/Semantic_Segmentation/vgg16/saved_model_no_weights'\n",
    "# WEIGHT_PATH = './vgg16/vgg16_weights.npz'\n",
    "NUM_CLASSES = 1\n",
    "LRATE = 0.001\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SHAPE = (101, 101, 3)\n",
    "LABEL_SHAPE = (101, 101)\n",
    "INPUT_SHAPE = (104, 104, 3)\n",
    "OUTPUT_SHAPE = (104, 104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimize(nn_last_layer, correct_label, learning_rate = LRATE, num_classes = NUM_CLASSES):\n",
    "#     logits = tf.reshape(nn_last_layer, (-1, num_classes), name=\"fcn_logits\")\n",
    "#     correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes))\n",
    "#     cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped[:])\n",
    "#     loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\") # actual loss value\n",
    "#     train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, name=\"fcn_train_op\")\n",
    "#     return logits, train_op, loss_op\n",
    "\n",
    "# def train_nn(sess, epochs, batch_size, data_handler, train_op,\n",
    "#              cross_entropy_loss, input_image,\n",
    "#              correct_label, phase_ph):\n",
    "    \n",
    "#     def check_and_delete_existing(directory):\n",
    "#         if os.path.exists(directory):\n",
    "#             os.system(\"rm -rf \"+directory)\n",
    "#         return directory\n",
    "    \n",
    "#     output_path = check_and_delete_existing(\"./Train\")\n",
    "#     train_summary_writer = tf.summary.FileWriter(output_path)\n",
    "    \n",
    "#     train_summary=tf.Summary()\n",
    "#     val_summary=tf.Summary()\n",
    "    \n",
    "#     # Initialize all variables\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "#     total_train_loss = 0\n",
    "#     total_val_loss = 0\n",
    "#     step = 0 \n",
    "#     for epoch in range(epochs):\n",
    "#         total_train_loss = 0\n",
    "#         total_val__loss = 0\n",
    "#         for X_batch, gt_batch in data_handler.gen_batch_function(bs = batch_size):\n",
    "#             step += 1\n",
    "            \n",
    "#             loss, _ = sess.run([cross_entropy_loss, train_op], \n",
    "#                                feed_dict={input_image: X_batch, \n",
    "#                                           correct_label: gt_batch,\n",
    "#                                           phase_ph: 1})\n",
    "            \n",
    "#             val_loss = sess.run([cross_entropy_loss], \n",
    "#                                 feed_dict={input_image: data_handler.val_feat_data, \n",
    "#                                            correct_label: data_handler.val_label_data, \n",
    "#                                            phase_ph: 1})\n",
    "            \n",
    "#             train_summary.value.add(tag='train_loss', simple_value = loss)\n",
    "#             val_summary.value.add(tag='val_loss', simple_value = val_loss[0])\n",
    "#             train_summary_writer.add_summary(train_summary, step)\n",
    "#             train_summary_writer.add_summary(val_summary, step)\n",
    "            \n",
    "#             # train_summary_writer.flush()\n",
    "#             total_train_loss += loss;\n",
    "#             total_val_loss += val_loss[0]\n",
    "#         print(\"EPOCH {} ...\".format(epoch + 1))\n",
    "#         print(\"Loss = {:.3f};  Val_loss = {:.3f}\".format(total_train_loss, total_val_loss))\n",
    "#         print()\n",
    "    \n",
    "#     graph = tf.get_default_graph()\n",
    "    \n",
    "#     output = graph.get_tensor_by_name('final_output:0')\n",
    "    \n",
    "#     train_pred = sess.run([output], \n",
    "#              feed_dict={input_image: data_handler.train_feat_data[:5], \n",
    "#                         correct_label: data_handler.train_label_data[:5], \n",
    "#                         phase_ph: 0})\n",
    "    \n",
    "#     test_pred = sess.run([output], \n",
    "#              feed_dict={input_image: data_handler.val_feat_data[:5], \n",
    "#                         correct_label: data_handler.val_label_data[:5], \n",
    "#                         phase_ph: 0})\n",
    "    \n",
    "#     return (data_handler.train_feat_data[:5], \n",
    "#             train_pred, data_handler.train_label_data[:5], \n",
    "#             data_handler.val_feat_data[:5],\n",
    "#             test_pred,\n",
    "#             data_handler.val_label_data[:5]\n",
    "#            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    d_processor = dh()\n",
    "    image_input = tf.placeholder(tf.float32,\n",
    "                          [None, *INPUT_SHAPE],\n",
    "                          name='image_input'\n",
    "                         )\n",
    "    \n",
    "    phase = tf.placeholder(tf.bool, name='phase') \n",
    "    # if no dropout will not be relevant\n",
    "    \n",
    "    vgg = vgg16_modified(image_input, sess)\n",
    "\n",
    "    correct_label = tf.placeholder(tf.float32, \n",
    "                                   [None, *OUTPUT_SHAPE], \n",
    "                                   name='correct_label'\n",
    "                                  )\n",
    "\n",
    "    logits, train_op, cross_entropy_loss = optimize(vgg.output, correct_label)\n",
    "    \n",
    "    (input_train,\n",
    "    train, \n",
    "    true_train, \n",
    "    input_test, \n",
    "    test, \n",
    "    true_test) \\\n",
    "    = train_nn(\n",
    "        sess,\n",
    "        EPOCHS,\n",
    "        BATCH_SIZE,\n",
    "        d_processor,\n",
    "        train_op, \n",
    "        cross_entropy_loss,\n",
    "        image_input,\n",
    "        correct_label,\n",
    "        phase\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_image(input_img, predict, true, ind, name):\n",
    "    \n",
    "    def softmax(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    predict = np.array(predict)\n",
    "    img = predict[0,ind,:,:,0]\n",
    "    img = np.array(list(map(softmax, img))\n",
    "                  )\n",
    "    thresh_img = img > 0.5\n",
    "    fig, ax = plt.subplots(1,4)\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title('sigmoid')\n",
    "    ax[1].imshow(thresh_img)\n",
    "    ax[1].set_title('threshold')\n",
    "    ax[2].imshow(true[ind])\n",
    "    ax[2].set_title('ground_truth')\n",
    "    ax[3].imshow(input_img[ind])\n",
    "    ax[3].set_title('input_image')\n",
    "    fig.suptitle(name + ' for image ' + str(ind))\n",
    "    \n",
    "    return None\n",
    "\n",
    "for i in range(5):\n",
    "    proc_image(input_train, train, true_train, i, name = 'train_image_result')\n",
    "\n",
    "for i in range(5):\n",
    "    proc_image(input_test, test, true_test, i, name = 'test_image_result')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
