{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_DIR = './data/train/images'\n",
    "LABELS_DIR = './data/train/masks'\n",
    "#VGG_PATH = '/home/paperspace/kaggle/Semantic_Segmentation/vgg16/saved_model_with_dropout'\n",
    "VGG_PATH = '/home/paperspace/kaggle/Semantic_Segmentation/vgg16/saved_model_no_weights'\n",
    "NUM_CLASSES = 1\n",
    "LRATE = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SHAPE = (101, 101, 3)\n",
    "LABEL_SHAPE = (101, 101)\n",
    "INPUT_SHAPE = (104, 104, 3)\n",
    "OUTPUT_SHAPE = (104, 104)\n",
    "# input different to the image dimensions due to a hack to make the layers symmetric when\n",
    "# deconvoluting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "class data_handling:\n",
    "    \n",
    "    def __init__(self, feat_path=FEAT_DIR, label_path=LABELS_DIR):\n",
    "        self.create_arrays(feat_path, label_path)\n",
    "        self.train_feat_data, \\\n",
    "        self.val_feat_data, \\\n",
    "        self.test_feat_data, \\\n",
    "        self.train_feat_data_filenames, \\\n",
    "        self.val_feat_data_filenames, \\\n",
    "        self.test_feat_data_filenames \\\n",
    "        = \\\n",
    "        self.split_data(self.feat_data, \n",
    "                        self.filenames)\n",
    "        \n",
    "        self.train_label_data, \\\n",
    "        self.val_label_data, \\\n",
    "        self.test_label_data, \\\n",
    "        _, _, _ = \\\n",
    "        self.split_data(self.label_data, \n",
    "                        self.filenames)\n",
    "    \n",
    "    def gen_batch_function(self, dataset='train',\n",
    "                           bs=BATCH_SIZE, num_batches=None):\n",
    "        \n",
    "        if dataset == 'train':\n",
    "            feat = self.train_feat_data\n",
    "            labels = self.train_label_data\n",
    "            \n",
    "        elif dataset == 'test':\n",
    "            feat = self.test_feat_data\n",
    "            labels = self.test_label_data\n",
    "            \n",
    "        if num_batches is None:\n",
    "            stop_iter = len(feat)//bs + 1\n",
    "        else:\n",
    "            stop_iter = num_batches\n",
    "        \n",
    "        batch = 0\n",
    "        \n",
    "        for i in range(stop_iter):\n",
    "            if batch != len(feat)//bs:\n",
    "                \n",
    "                st = batch*bs; end = (batch+1)*bs;\n",
    "                \n",
    "                yield (feat[st:end,:].astype('float32')\\\n",
    "                - self.get_mean()), \\\n",
    "                labels[st:end,:].astype('float32')\n",
    "                \n",
    "                batch += 1\n",
    "            else:\n",
    "                yield feat[batch*bs:(len(feat)),:].astype('float32')\\\n",
    "                 - self.get_mean(), \\\n",
    "                labels[batch*bs:(len(feat)),:].astype('float32')\n",
    "\n",
    "    def create_arrays(self, feat_path, label_path):\n",
    "        \n",
    "        files = [f for f in \\\n",
    "                       listdir(feat_path) if isfile(join(feat_path, f))]\n",
    "\n",
    "        feat_data = np.zeros((len(files), *INPUT_SHAPE)).astype('int')\n",
    "        label_data = np.zeros((len(files), *OUTPUT_SHAPE)).astype('int')\n",
    "            \n",
    "        for i in range(len(files)):\n",
    "            feat_data[i,\n",
    "                 :IMAGE_SHAPE[0],\n",
    "                 :IMAGE_SHAPE[1],\n",
    "                 :] = np.array(Image.open(feat_path + '/'+ files[i])) \n",
    "            label_data[i,\n",
    "                 :IMAGE_SHAPE[0],\n",
    "                 :IMAGE_SHAPE[1]\n",
    "                ] = np.array(Image.open(label_path + '/'+ files[i]))                \n",
    "        \n",
    "        self.feat_data, self.label_data, self.filenames = self.shuffle(feat_data,\n",
    "                                                 label_data,\n",
    "                                                 pd.Series(files))\n",
    "        \n",
    "        self.label_data = self.label_data/65535.0\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_data(data, \\\n",
    "                   filenames, \\\n",
    "                   val_split = 0.05,\n",
    "                   split = 0.8\n",
    "                  ):\n",
    "        \n",
    "        train_end = int(len(data)*(split - val_split))\n",
    "        val_end = int(len(data)*split)\n",
    "\n",
    "        train_feat = data[:train_end]\n",
    "        train_feat_filenames = filenames[:train_end]\n",
    "\n",
    "        val_data = data[train_end:val_end]\n",
    "        val_data_filenames = filenames[train_end:val_end]\n",
    "\n",
    "        test_data = data[val_end:]\n",
    "        test_data_filenames = filenames[val_end:]\n",
    "\n",
    "        return train_feat, val_data, test_data, \\\n",
    "    train_feat_filenames, val_data_filenames, test_data_filenames\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mean():\n",
    "        x = np.zeros((1,1,1,3))\n",
    "        x[0,0,0,:]= np.array([120.346, 120.346, 120.346])\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_std():\n",
    "        return 27.60\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle(feat_data, label_data, filenames):\n",
    "        ind = np.random.choice(len(feat_data),\n",
    "                               len(feat_data),\n",
    "                               replace=False\n",
    "                              )\n",
    "        return feat_data[ind], label_data[ind], filenames.loc[ind]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg(sess, vgg_path = VGG_PATH):\n",
    "  \n",
    "   # load the model and weights\n",
    "    model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n",
    "\n",
    "   # Get Tensors to be returned from graph\n",
    "    graph = tf.get_default_graph()\n",
    "    image_input = graph.get_tensor_by_name('image_input:0')\n",
    "   \n",
    "    #keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    phase = graph.get_tensor_by_name('phase:0')\n",
    "    layer3 = graph.get_tensor_by_name('conv2_1:0')\n",
    "    layer4 = graph.get_tensor_by_name('pool_2_bn:0')\n",
    "    layer7 = graph.get_tensor_by_name('pool_3_bn:0')\n",
    "\n",
    "    return image_input, layer3, layer4, layer7, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes = NUM_CLASSES):\n",
    "   \n",
    "    # Use a shorter variable name for simplicity\n",
    "    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
    "\n",
    "    # Apply 1x1 convolution in place of fully connected layer\n",
    "    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name=\"fcn8\")\n",
    "    \n",
    "    \n",
    "    # Upsample fcn8 with size depth=(4096?) to match size of layer 4 so that we can add skip connection with 4th layer\n",
    "    fcn9 = tf.layers.conv2d_transpose(\n",
    "        fcn8, filters=layer4.get_shape().as_list()[-1],\n",
    "        kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\"\n",
    "    )\n",
    "\n",
    "    # Add a skip connection between current final layer fcn8 and 4th layer\n",
    "    fcn9_skip_connected = tf.add(fcn9, layer4, name=\"fcn9_plus_vgg_layer4\")\n",
    "\n",
    "    # Upsample again\n",
    "    fcn10 = tf.layers.conv2d_transpose(\n",
    "        fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n",
    "        kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\"\n",
    "    )\n",
    "\n",
    "    # Add skip connection\n",
    "    fcn10_skip_connected = tf.add(fcn10, layer3, name=\"fcn10_plus_vgg_layer3\")\n",
    "    \n",
    "    # Upsample again\n",
    "    fcn11 = tf.layers.conv2d_transpose(\n",
    "        fcn10_skip_connected, filters=NUM_CLASSES,\n",
    "        kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn11\"\n",
    "    )\n",
    "    \n",
    "    fcn11 = tf.identity(fcn11, name = 'final_output')\n",
    "    \n",
    "    return fcn11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate = LRATE, num_classes = NUM_CLASSES):\n",
    "  \n",
    "  # Reshape 4D tensors to 2D, each row represents a pixel, each column a class\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes), name=\"fcn_logits\")\n",
    "    correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes))\n",
    "\n",
    "    # Calculate distance from actual labels using cross entropy\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped[:])\n",
    "    # Take mean for total loss\n",
    "    loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\")\n",
    "\n",
    "    # The model implements this operation to find the weights/parameters that would yield correct pixel labels\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, name=\"fcn_train_op\")\n",
    "\n",
    "    return logits, train_op, loss_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(sess, epochs, batch_size, data_handler, train_op,\n",
    "             cross_entropy_loss, input_image,\n",
    "             correct_label, phase_ph):\n",
    "    \n",
    "    output_path = \"./Train\"\n",
    "    train_summary_writer = tf.summary.FileWriter(output_path)\n",
    "    \n",
    "    train_summary=tf.Summary()\n",
    "    val_summary=tf.Summary()\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "    step = 0 \n",
    "    for epoch in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_val__loss = 0\n",
    "        for X_batch, gt_batch in data_handler.gen_batch_function(bs = batch_size):\n",
    "            step += 1\n",
    "            \n",
    "            loss, _ = sess.run([cross_entropy_loss, train_op], \n",
    "                               feed_dict={input_image: X_batch, \n",
    "                                          correct_label: gt_batch,\n",
    "                                          phase_ph: 1})\n",
    "            \n",
    "            val_loss = sess.run([cross_entropy_loss], \n",
    "                                feed_dict={input_image: data_handler.val_feat_data, \n",
    "                                           correct_label: data_handler.val_label_data, \n",
    "                                           phase_ph: 1})\n",
    "            \n",
    "            train_summary.value.add(tag='train_loss', simple_value = loss)\n",
    "            val_summary.value.add(tag='val_loss', simple_value = val_loss[0])\n",
    "            train_summary_writer.add_summary(train_summary, step)\n",
    "            train_summary_writer.add_summary(val_summary, step)\n",
    "            \n",
    "            # train_summary_writer.flush()\n",
    "            total_train_loss += loss;\n",
    "            total_val_loss += val_loss[0]\n",
    "        print(\"EPOCH {} ...\".format(epoch + 1))\n",
    "        print(\"Loss = {:.3f};  Val_loss = {:.3f}\".format(total_train_loss, total_val_loss))\n",
    "        print()\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    output = graph.get_tensor_by_name('final_output:0')\n",
    "    \n",
    "    train_pred = sess.run([output], \n",
    "             feed_dict={input_image: data_handler.train_feat_data[:5], \n",
    "                        correct_label: data_handler.train_label_data[:5], \n",
    "                        phase_ph: 0})\n",
    "    \n",
    "    test_pred = sess.run([output], \n",
    "             feed_dict={input_image: data_handler.val_feat_data[:5], \n",
    "                        correct_label: data_handler.val_label_data[:5], \n",
    "                        phase_ph: 0})\n",
    "    \n",
    "    return data_handler.train_feat_data[:5], train_pred, data_handler.train_label_data[:5], \\\n",
    "data_handler.val_feat_data[:5], test_pred, data_handler.val_label_data[:5]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(eps=EPOCHS):\n",
    "  \n",
    "  d_proc = data_handling()\n",
    "  \n",
    "  with tf.Session() as session:\n",
    "    \n",
    "    correct_label = tf.placeholder(tf.float32, [None, *OUTPUT_SHAPE], name='correct_label')\n",
    "    \n",
    "    image_input, layer3, layer4, layer7, ph = load_vgg(session)\n",
    "    \n",
    "    model_output = layers(layer3, layer4, layer7, num_classes = 1)\n",
    "\n",
    "    logits, train_op, cross_entropy_loss = optimize(model_output, correct_label)\n",
    "\n",
    "    print(\"Model build successful, starting training\")\n",
    "\n",
    "    # Train the neural network\n",
    "    return train_nn(session, eps, BATCH_SIZE, d_proc, \n",
    "             train_op, cross_entropy_loss, image_input,\n",
    "             correct_label, ph)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/paperspace/kaggle/Semantic_Segmentation/vgg16/saved_model_no_weights/variables/variables\n",
      "Model build successful, starting training\n",
      "EPOCH 1 ...\n",
      "Loss = 18.619;  Val_loss = 28.755\n",
      "\n",
      "EPOCH 2 ...\n",
      "Loss = 14.271;  Val_loss = 54.777\n",
      "\n",
      "EPOCH 3 ...\n",
      "Loss = 12.923;  Val_loss = 78.340\n",
      "\n",
      "EPOCH 4 ...\n",
      "Loss = 11.972;  Val_loss = 100.798\n",
      "\n",
      "EPOCH 5 ...\n",
      "Loss = 11.254;  Val_loss = 121.900\n",
      "\n",
      "EPOCH 6 ...\n",
      "Loss = 10.634;  Val_loss = 142.532\n",
      "\n",
      "EPOCH 7 ...\n",
      "Loss = 10.190;  Val_loss = 163.637\n",
      "\n",
      "EPOCH 8 ...\n",
      "Loss = 9.763;  Val_loss = 185.074\n",
      "\n",
      "EPOCH 9 ...\n",
      "Loss = 9.485;  Val_loss = 207.563\n",
      "\n",
      "EPOCH 10 ...\n",
      "Loss = 8.939;  Val_loss = 230.457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_train, train, true_train, input_test, test, true_test = run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_image(input_img, predict, true, ind, name):\n",
    "    \n",
    "    def softmax(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    predict = np.array(predict)\n",
    "    img = predict[0,ind,:,:,0]\n",
    "    img = np.array(list(map(softmax, img))\n",
    "                  )\n",
    "    thresh_img = img > 0.5\n",
    "    fig, ax = plt.subplots(1,4)\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title('sigmoid')\n",
    "    ax[1].imshow(thresh_img)\n",
    "    ax[1].set_title('threshold')\n",
    "    ax[2].imshow(true[ind])\n",
    "    ax[2].set_title('ground_truth')\n",
    "    ax[3].imshow(input_img[ind])\n",
    "    ax[3].set_title('input_image')\n",
    "    fig.suptitle(name + ' for image ' + str(ind))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def softmax(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "predict = np.array(predict)\n",
    "img = predict[0,ind,:,:,0]\n",
    "img = np.array(list(map(softmax, img))\n",
    "\n",
    "for i in range(5):\n",
    "    proc_image(input_train, train, true_train, i, name = 'train_image_result')\n",
    "\n",
    "for i in range(5):\n",
    "    proc_image(input_test, test, true_test, i, name = 'test_image_result')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
