{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FEAT_DIR = './data/train/images'\n",
    "TRAIN_LABELS_DIR = './data/train/masks'\n",
    "VGG_PATH = '/home/paperspace/kaggle/Semantic_Segmentation/vgg16/saved_model_with_dropout'\n",
    "NUM_CLASSES = 1\n",
    "LRATE = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SHAPE = (101, 101, 3)\n",
    "LABEL_SHAPE = (101, 101)\n",
    "INPUT_SHAPE = (104, 104, 3)\n",
    "OUTPUT_SHAPE = (104, 104)\n",
    "# input different to the image dimensions due to a hack to make the layers symmetric when\n",
    "# deconvoluting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "class data_handling:\n",
    "    \n",
    "    def __init__(self, train_feat_path, train_label_path):\n",
    "        self.train_feat_path = train_feat_path\n",
    "        self.train_label_path = train_label_path\n",
    "        \n",
    "        self.train_feat_data, \\\n",
    "        self.val_feat_data, \\\n",
    "        self.test_feat_data = \\\n",
    "        self.split_data(self.create_array(train_feat_path))\n",
    "        self.train_label_data, \\\n",
    "        self.val_label_data, \\\n",
    "        self.test_label_data =\\\n",
    "        self.split_data(\n",
    "            self.create_array(train_label_path, mode='label')/65535.0)\n",
    "    \n",
    "    def gen_batch_function(self, dataset='train',\n",
    "                           bs=BATCH_SIZE, num_batches=None):\n",
    "        \n",
    "        if dataset == 'train':\n",
    "            feat = self.train_feat_data\n",
    "            labels = self.train_label_data\n",
    "            \n",
    "        elif dataset == 'test':\n",
    "            feat = self.test_feat_data\n",
    "            labels = self.test_label_data\n",
    "            \n",
    "        if num_batches is None:\n",
    "            stop_iter = len(feat)//bs + 1\n",
    "        else:\n",
    "            stop_iter = num_batches\n",
    "        \n",
    "        batch = 0\n",
    "        \n",
    "        for i in range(stop_iter):\n",
    "            if batch != len(feat)//bs:\n",
    "                \n",
    "                st = batch*bs; end = (batch+1)*bs;\n",
    "                \n",
    "                yield (feat[st:end,:].astype('float32')\\\n",
    "                - self.get_mean()), \\\n",
    "                labels[st:end,:].astype('float32')\n",
    "                \n",
    "                batch += 1\n",
    "            else:\n",
    "                yield feat[batch*bs:(len(feat)),:].astype('float32')\\\n",
    "                 - self.get_mean(), \\\n",
    "                labels[batch*bs:(len(feat)),:].astype('float32')\n",
    "\n",
    "    def create_array(self, path, mode = 'train'):\n",
    "        files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        \n",
    "        if mode=='train':\n",
    "            data = np.zeros((len(files), *INPUT_SHAPE)).astype('int')\n",
    "        elif mode=='label':\n",
    "            data = np.zeros((len(files), *OUTPUT_SHAPE)).astype('int')\n",
    "            \n",
    "        for i in range(len(files)):\n",
    "            if mode == 'train':\n",
    "                data[i,\n",
    "                     :IMAGE_SHAPE[0],\n",
    "                     :IMAGE_SHAPE[1],\n",
    "                     :] = np.array(Image.open(path + '/'+ files[i])) \n",
    "            elif mode == 'label':\n",
    "                data[i,\n",
    "                     :IMAGE_SHAPE[0],\n",
    "                     :IMAGE_SHAPE[1]\n",
    "                    ] = np.array(Image.open(path + '/'+ files[i]))                \n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mean():\n",
    "        x = np.zeros((1,1,1,3))\n",
    "        x[0,0,0,:]= np.array([120.346, 120.346, 120.346])\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_std():\n",
    "        return 27.60\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle(data):\n",
    "        ind = np.random.choice(len(data),len(data), replace=False)\n",
    "        return data[ind]\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_data(data, val_split = 0.05, split = 0.8):\n",
    "        train_end = int(len(data)*(split - val_split))\n",
    "        val_end = int(len(data)*split)\n",
    "        train_feat = data[:train_end]\n",
    "        val_data = data[train_end:val_end]\n",
    "        test_data = data[val_end:]\n",
    "        return train_feat, val_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg(sess, vgg_path = VGG_PATH):\n",
    "  \n",
    "   # load the model and weights\n",
    "    model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n",
    "\n",
    "   # Get Tensors to be returned from graph\n",
    "    graph = tf.get_default_graph()\n",
    "    image_input = graph.get_tensor_by_name('image_input:0')\n",
    "   \n",
    "    #keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "    phase = graph.get_tensor_by_name('phase:0')\n",
    "    layer3 = graph.get_tensor_by_name('conv2_1:0')\n",
    "    layer4 = graph.get_tensor_by_name('pool_2_bn:0')\n",
    "    layer7 = graph.get_tensor_by_name('pool_3_bn:0')\n",
    "\n",
    "    return image_input, layer3, layer4, layer7, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes = NUM_CLASSES):\n",
    "   \n",
    "    # Use a shorter variable name for simplicity\n",
    "    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
    "\n",
    "    # Apply 1x1 convolution in place of fully connected layer\n",
    "    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name=\"fcn8\")\n",
    "\n",
    "    # Upsample fcn8 with size depth=(4096?) to match size of layer 4 so that we can add skip connection with 4th layer\n",
    "    fcn9 = tf.layers.conv2d_transpose(\n",
    "        fcn8, filters=layer4.get_shape().as_list()[-1],\n",
    "        kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\"\n",
    "    )\n",
    "\n",
    "    # Add a skip connection between current final layer fcn8 and 4th layer\n",
    "    fcn9_skip_connected = tf.add(fcn9, layer4, name=\"fcn9_plus_vgg_layer4\")\n",
    "\n",
    "    # Upsample again\n",
    "    fcn10 = tf.layers.conv2d_transpose(\n",
    "        fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n",
    "        kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\"\n",
    "    )\n",
    "\n",
    "    # Add skip connection\n",
    "    fcn10_skip_connected = tf.add(fcn10, layer3, name=\"fcn10_plus_vgg_layer3\")\n",
    "    \n",
    "    # Upsample again\n",
    "    fcn11 = tf.layers.conv2d_transpose(\n",
    "        fcn10_skip_connected, filters=NUM_CLASSES,\n",
    "        kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn11\"\n",
    "    )\n",
    "\n",
    "    return fcn11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate = LRATE, num_classes = NUM_CLASSES):\n",
    "  \n",
    "  # Reshape 4D tensors to 2D, each row represents a pixel, each column a class\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes), name=\"fcn_logits\")\n",
    "    correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes))\n",
    "\n",
    "    # Calculate distance from actual labels using cross entropy\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped[:])\n",
    "    # Take mean for total loss\n",
    "    loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\")\n",
    "\n",
    "    # The model implements this operation to find the weights/parameters that would yield correct pixel labels\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, name=\"fcn_train_op\")\n",
    "\n",
    "    return logits, train_op, loss_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(sess, epochs, batch_size, data_handler, train_op,\n",
    "             cross_entropy_loss, input_image,\n",
    "             correct_label, phase_ph):\n",
    "    \n",
    "    output_path = \"./Train\"\n",
    "    train_summary_writer = tf.summary.FileWriter(output_path)\n",
    "    \n",
    "    train_summary=tf.Summary()\n",
    "    val_summary=tf.Summary()\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "    step = 0 \n",
    "    for epoch in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_val__loss = 0\n",
    "        for X_batch, gt_batch in data_handler.gen_batch_function(bs = batch_size):\n",
    "            step += 1\n",
    "            \n",
    "            loss, _ = sess.run([cross_entropy_loss, train_op], \n",
    "                               feed_dict={input_image: X_batch, \n",
    "                                          correct_label: gt_batch,\n",
    "                                          phase_ph: 1})\n",
    "            \n",
    "            val_loss = sess.run([cross_entropy_loss], \n",
    "                                feed_dict={input_image: data_handler.val_feat_data, \n",
    "                                           correct_label: data_handler.val_label_data, \n",
    "                                           phase_ph: 0})\n",
    "            \n",
    "            train_summary.value.add(tag='train_loss', simple_value = loss)\n",
    "            val_summary.value.add(tag='val_loss', simple_value = val_loss[0])\n",
    "            train_summary_writer.add_summary(train_summary, step)\n",
    "            train_summary_writer.add_summary(val_summary, step)\n",
    "            \n",
    "            # train_summary_writer.flush()\n",
    "            total_train_loss += loss;\n",
    "            total_val_loss += val_loss[0]\n",
    "        print(\"EPOCH {} ...\".format(epoch + 1))\n",
    "        print(\"Loss = {:.3f};  Val_loss = {:.3f}\".format(total_train_loss, total_val_loss))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "  \n",
    "  d_proc = data_handling(TRAIN_FEAT_DIR, TRAIN_LABELS_DIR)\n",
    "  \n",
    "  with tf.Session() as session:\n",
    "    \n",
    "    correct_label = tf.placeholder(tf.float32, [None, *OUTPUT_SHAPE], name='correct_label')\n",
    "    \n",
    "    image_input, layer3, layer4, layer7, ph = load_vgg(session)\n",
    "    \n",
    "    model_output = layers(layer3, layer4, layer7, num_classes = 1)\n",
    "\n",
    "    logits, train_op, cross_entropy_loss = optimize(model_output, correct_label)\n",
    "\n",
    "    print(\"Model build successful, starting training\")\n",
    "\n",
    "    # Train the neural network\n",
    "    train_nn(session, EPOCHS, BATCH_SIZE, d_proc, \n",
    "             train_op, cross_entropy_loss, image_input,\n",
    "             correct_label, ph)\n",
    "      \n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     phase = graph.get_tensor_by_name('phase:0')\n",
    "#     layer3 = graph.get_tensor_by_name('conv2_1:0')\n",
    "#     layer4 = graph.get_tensor_by_name('batch_norm_2:0')\n",
    "#     layer7 = graph.get_tensor_by_name('batch_norm_3:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<contextlib._GeneratorContextManager object at 0x7f307c09f908>\n"
     ]
    }
   ],
   "source": [
    "graph.name_scope('batch_norm_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'batch_norm_2:0' refers to a Tensor which does not exist. The operation, 'batch_norm_2', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-16dee825f373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_norm_2:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3513\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3514\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3515\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3341\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3379\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   3380\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3381\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3382\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'batch_norm_2:0' refers to a Tensor which does not exist. The operation, 'batch_norm_2', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "graph.get_tensor_by_name('batch_norm_2:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cond_context',\n",
       " 'model_variables',\n",
       " 'trainable_variables',\n",
       " 'update_ops',\n",
       " 'variables']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_all_collection_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1_1/weights:0' shape=(3, 3, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv1_1/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv1_2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv1_2/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_1/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_1/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_1/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_1/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2_1/biases:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2_2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2_2/biases:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_2/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_2/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_2/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_2/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv3_1/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'conv3_1/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv3_2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'conv3_2/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv3_3/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'conv3_3/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_3/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_3/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_3/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_norm_3/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv4_1/weights:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'conv4_1/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv4_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'conv4_2/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv4_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'conv4_3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv5_1/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'conv5_1/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv5_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'conv5_2/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv5_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'conv5_3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1/weights:0' shape=(8192, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1/biases:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc2/weights:0' shape=(4096, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'fc2/biases:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc3/weights:0' shape=(4096, 1000) dtype=float32_ref>,\n",
       " <tf.Variable 'fc3/biases:0' shape=(1000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_collection('variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/paperspace/kaggle/Semantic_Segmentation/vgg16/saved_model_with_dropout/variables/variables\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The name 'batch_norm_2:0' refers to a Tensor which does not exist. The operation, 'batch_norm_2', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-aba28b2e795a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcorrect_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mOUTPUT_SHAPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'correct_label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cbb775b9f4c2>\u001b[0m in \u001b[0;36mload_vgg\u001b[0;34m(sess, vgg_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'phase:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2_1:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlayer4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_norm_2:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlayer7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_norm_3:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3513\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3514\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3515\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3341\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3379\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   3380\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3381\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3382\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'batch_norm_2:0' refers to a Tensor which does not exist. The operation, 'batch_norm_2', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
